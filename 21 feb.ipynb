{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc47e800-8b52-46e0-bbb9-3d0bf7bf4153",
   "metadata": {},
   "outputs": [],
   "source": [
    "1)Web scraping is an automatic method to obtain large amounts of data from websites. Most of this data is unstructured data in an HTML format which is then converted into structured data in a spreadsheet or a database so that it can be used in various applications. There are many different ways to perform web scraping to obtain data from websites. These include using online services, particular API’s or even creating your code for web scraping from scratch. Many large websites, like Google, Twitter, Facebook, StackOverflow, etc. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47e92072-e075-43fe-a58f-5d454b0fbeac",
   "metadata": {},
   "outputs": [],
   "source": [
    "2)What are the different ways of web scraping?\n",
    "Data Scraping Techniques\n",
    "HTML Parsing. HTML parsing involves the use of JavaScript to target a linear or nested HTML page. ...\n",
    "DOM Parsing. ...\n",
    "Vertical Aggregation. ...\n",
    "XPath. ...\n",
    "Google Sheets. ...\n",
    "Rate Limit User Requests. ...\n",
    "Mitigate High-Volume Requesters with CAPTCHAs. ...\n",
    "Regularly Modify HTML Markup.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "813e5926-cb6b-45a2-9013-3314c1776147",
   "metadata": {},
   "outputs": [],
   "source": [
    "3)Beautiful Soup is a Python package for parsing HTML and XML documents (including having malformed markup, i.e. non-closed tags, so named after tag soup). It creates a parse tree for parsed pages that can be used to extract data from HTML, which is useful for web scraping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4a54698-b4e6-424f-9613-4782c5d7ed44",
   "metadata": {},
   "outputs": [],
   "source": [
    "4)Flask is a lightweight framework to build websites. We'll use this to parse our collected data and display it as HTML in a new HTML file. The requests module allows us to send http requests to the website we want to scrape. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eac480c-9ea9-4fd0-894c-a8b2dfc45a23",
   "metadata": {},
   "outputs": [],
   "source": [
    "5)1. AWS EC2 – Elastic Compute Cloud\n",
    "Amazon Elastic Compute Cloud (Amazon EC2) is a web service that provides secure, resizable compute capacity in the cloud. Amazon EC2’s simple web service interface allows you to obtain and configure capacity quickly and with minimum effort.\n",
    "        \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
